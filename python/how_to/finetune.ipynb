{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune with Pre-trained Models\n",
    "\n",
    "In practice the dataset we use is relative small, so that we do not train an neural network from scratch, namely staring from random initialized parameters. Instead, it is common to train a neural network on a large-scale dataset and then use it either as an initialization or a fixed feature extractor. On [predict.ipynb](./predict.ipynb) we explained how to do the feature extraction, this tutorial will focus on how to use pre-trained model to fine tune a new network.\n",
    "\n",
    "The idea of fine-tune is that, we take a pre-trained model, replace the last fully-connected layer with new one, which outputs the desired number of classes and initializes with random values. Then we train as normal except that we may often use a smaller learning rate since we may already very close the final result. \n",
    "\n",
    "We will use pre-trained models on the Imagenet dataset to fine-tune the smaller caltech-256 dataset as an example. But note that it can be used to other datasets as well, even for quite different applications such as face identification. \n",
    "\n",
    "## Prepare data\n",
    "\n",
    "We follow the standard protocal to sample 60 images from each class as the training set, and the rest for the validation set. We resize images into 256x256 size and pack them into the rec file. The scripts to prepare the data is as following. \n",
    "\n",
    "\n",
    "```sh\n",
    "wget http://www.vision.caltech.edu/Image_Datasets/Caltech256/256_ObjectCategories.tar\n",
    "tar -xf 256_ObjectCategories.tar\n",
    "\n",
    "mkdir -p caltech_256_train_60\n",
    "for i in 256_ObjectCategories/*; do\n",
    "    c=`basename $i`\n",
    "    mkdir -p caltech_256_train_60/$c\n",
    "    for j in `ls $i/*.jpg | shuf | head -n 60`; do\n",
    "        mv $j caltech_256_train_60/$c/\n",
    "    done\n",
    "done\n",
    "\n",
    "python ~/mxnet/tools/im2rec.py --list True --recursive True caltech-256-60-train caltech_256_train_60/\n",
    "python ~/mxnet/tools/im2rec.py --list True --recursive True caltech-256-60-val 256_ObjectCategories/\n",
    "python ~/mxnet/tools/im2rec.py --resize 256 --quality 90 --num-thread 16 caltech-256-60-val 256_ObjectCategories/\n",
    "python ~/mxnet/tools/im2rec.py --resize 256 --quality 90 --num-thread 16 caltech-256-60-train caltech_256_train_60/\n",
    "```\n",
    "\n",
    "The following codes download the pre-generated rec files. It may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "download('http://data.mxnet.io/data/caltech-256/caltech-256-60-train.rec')\n",
    "download('http://data.mxnet.io/data/caltech-256/caltech-256-60-val.rec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next we define the function which returns the data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './caltech-256-60-train.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './caltech-256-60-val.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we download a pretrained 50-layer ResNet model and load into memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/50-layers/resnet-50', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "We first define a function which replaces the the last fully-connected layer for a given network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a module. We first call `init_params` to randomly initialize parameters, next use `set_params` to replace all parameters except for the last fully-connected layer with pre-trained model. Then we can start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-21 05:03:44,995 Already binded, ignoring bind()\n",
      "2016-10-21 05:04:19,726 Epoch[0] Batch [50]\tSpeed: 47.31 samples/sec\tTrain-accuracy=0.017770\n",
      "2016-10-21 05:04:53,733 Epoch[0] Batch [100]\tSpeed: 47.05 samples/sec\tTrain-accuracy=0.108750\n",
      "2016-10-21 05:05:27,859 Epoch[0] Batch [150]\tSpeed: 46.89 samples/sec\tTrain-accuracy=0.218125\n",
      "2016-10-21 05:06:01,975 Epoch[0] Batch [200]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.371875\n",
      "2016-10-21 05:06:36,094 Epoch[0] Batch [250]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.423125\n",
      "2016-10-21 05:07:10,221 Epoch[0] Batch [300]\tSpeed: 46.89 samples/sec\tTrain-accuracy=0.527500\n",
      "2016-10-21 05:07:44,333 Epoch[0] Batch [350]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.563125\n",
      "2016-10-21 05:08:18,438 Epoch[0] Batch [400]\tSpeed: 46.92 samples/sec\tTrain-accuracy=0.606250\n",
      "2016-10-21 05:08:52,545 Epoch[0] Batch [450]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.651875\n",
      "2016-10-21 05:09:13,694 Epoch[0] Train-accuracy=0.645161\n",
      "2016-10-21 05:09:13,695 Epoch[0] Time cost=328.698\n",
      "2016-10-21 05:10:48,969 Epoch[0] Validation-accuracy=0.699671\n",
      "2016-10-21 05:11:23,327 Epoch[1] Batch [50]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.716299\n",
      "2016-10-21 05:11:57,431 Epoch[1] Batch [100]\tSpeed: 46.92 samples/sec\tTrain-accuracy=0.718750\n",
      "2016-10-21 05:12:31,541 Epoch[1] Batch [150]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.733750\n",
      "2016-10-21 05:13:05,630 Epoch[1] Batch [200]\tSpeed: 46.94 samples/sec\tTrain-accuracy=0.755625\n",
      "2016-10-21 05:13:39,737 Epoch[1] Batch [250]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.749375\n",
      "2016-10-21 05:14:13,832 Epoch[1] Batch [300]\tSpeed: 46.93 samples/sec\tTrain-accuracy=0.770000\n",
      "2016-10-21 05:14:47,934 Epoch[1] Batch [350]\tSpeed: 46.92 samples/sec\tTrain-accuracy=0.793750\n",
      "2016-10-21 05:15:22,030 Epoch[1] Batch [400]\tSpeed: 46.93 samples/sec\tTrain-accuracy=0.780625\n",
      "2016-10-21 05:15:56,118 Epoch[1] Batch [450]\tSpeed: 46.94 samples/sec\tTrain-accuracy=0.794375\n",
      "2016-10-21 05:16:17,258 Epoch[1] Train-accuracy=0.770161\n",
      "2016-10-21 05:16:17,259 Epoch[1] Time cost=328.287\n",
      "2016-10-21 05:17:52,413 Epoch[1] Validation-accuracy=0.769868\n",
      "2016-10-21 05:18:26,767 Epoch[2] Batch [50]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.806985\n",
      "2016-10-21 05:19:00,883 Epoch[2] Batch [100]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.819375\n",
      "2016-10-21 05:19:34,992 Epoch[2] Batch [150]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.821250\n",
      "2016-10-21 05:20:09,113 Epoch[2] Batch [200]\tSpeed: 46.89 samples/sec\tTrain-accuracy=0.826875\n",
      "2016-10-21 05:20:43,209 Epoch[2] Batch [250]\tSpeed: 46.93 samples/sec\tTrain-accuracy=0.813750\n",
      "2016-10-21 05:21:17,315 Epoch[2] Batch [300]\tSpeed: 46.92 samples/sec\tTrain-accuracy=0.839375\n",
      "2016-10-21 05:21:51,435 Epoch[2] Batch [350]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.834375\n",
      "2016-10-21 05:22:25,531 Epoch[2] Batch [400]\tSpeed: 46.93 samples/sec\tTrain-accuracy=0.841875\n",
      "2016-10-21 05:22:59,647 Epoch[2] Batch [450]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.850000\n",
      "2016-10-21 05:23:20,786 Epoch[2] Train-accuracy=0.835685\n",
      "2016-10-21 05:23:20,787 Epoch[2] Time cost=328.373\n",
      "2016-10-21 05:24:54,935 Epoch[2] Validation-accuracy=0.790216\n",
      "2016-10-21 05:25:29,291 Epoch[3] Batch [50]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.850490\n",
      "2016-10-21 05:26:03,408 Epoch[3] Batch [100]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.866875\n",
      "2016-10-21 05:26:37,526 Epoch[3] Batch [150]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.860000\n",
      "2016-10-21 05:27:11,629 Epoch[3] Batch [200]\tSpeed: 46.92 samples/sec\tTrain-accuracy=0.873750\n",
      "2016-10-21 05:27:45,736 Epoch[3] Batch [250]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.855625\n",
      "2016-10-21 05:28:19,825 Epoch[3] Batch [300]\tSpeed: 46.94 samples/sec\tTrain-accuracy=0.877500\n",
      "2016-10-21 05:28:53,950 Epoch[3] Batch [350]\tSpeed: 46.89 samples/sec\tTrain-accuracy=0.881875\n",
      "2016-10-21 05:29:28,060 Epoch[3] Batch [400]\tSpeed: 46.91 samples/sec\tTrain-accuracy=0.870625\n",
      "2016-10-21 05:30:02,175 Epoch[3] Batch [450]\tSpeed: 46.90 samples/sec\tTrain-accuracy=0.873750\n",
      "2016-10-21 05:30:23,322 Epoch[3] Train-accuracy=0.882056\n",
      "2016-10-21 05:30:23,323 Epoch[3] Time cost=328.387\n",
      "2016-10-21 05:31:58,284 Epoch[3] Validation-accuracy=0.805000\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size):\n",
    "    mod = mx.mod.Module(symbol=new_sym, context=mx.gpu())\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing=True)\n",
    "    mod.fit(train, val, \n",
    "        num_epoch=4,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 50),        \n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.01},\n",
    "        eval_metric='acc')    \n",
    "    \n",
    "batch_size = 32\n",
    "(train, val) = get_iterators(batch_size)\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, 256)\n",
    "fit(new_sym, new_args, aux_params, train, val, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As can be seen, even for 4 data epochs, we can get 80% validation accuracy. It matches the state-of-the-art results training on caltech-256 alone, e.g. [78% by VGG group](http://www.robots.ox.ac.uk/~vgg/research/deep_eval/). \n",
    "\n",
    "Next we try to use another pretrained model, which use more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-10-21 05:37:13,786 Already binded, ignoring bind()\n",
      "2016-10-21 05:38:35,521 Epoch[0] Batch [50]\tSpeed: 20.12 samples/sec\tTrain-accuracy=0.322304\n",
      "2016-10-21 05:39:55,822 Epoch[0] Batch [100]\tSpeed: 19.93 samples/sec\tTrain-accuracy=0.611875\n",
      "2016-10-21 05:41:16,128 Epoch[0] Batch [150]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.678125\n",
      "2016-10-21 05:42:36,450 Epoch[0] Batch [200]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.713750\n",
      "2016-10-21 05:43:56,716 Epoch[0] Batch [250]\tSpeed: 19.93 samples/sec\tTrain-accuracy=0.706875\n",
      "2016-10-21 05:45:17,020 Epoch[0] Batch [300]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.739375\n",
      "2016-10-21 05:46:37,309 Epoch[0] Batch [350]\tSpeed: 19.93 samples/sec\tTrain-accuracy=0.743125\n",
      "2016-10-21 05:47:57,625 Epoch[0] Batch [400]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.738750\n",
      "2016-10-21 05:49:17,935 Epoch[0] Batch [450]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.746250\n",
      "2016-10-21 05:50:07,737 Epoch[0] Train-accuracy=0.735887\n",
      "2016-10-21 05:50:07,738 Epoch[0] Time cost=773.950\n",
      "2016-10-21 05:53:47,807 Epoch[0] Validation-accuracy=0.721519\n",
      "2016-10-21 05:55:08,658 Epoch[1] Batch [50]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.805147\n",
      "2016-10-21 05:56:28,962 Epoch[1] Batch [100]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.819375\n",
      "2016-10-21 05:57:49,271 Epoch[1] Batch [150]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.825000\n",
      "2016-10-21 05:59:09,601 Epoch[1] Batch [200]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.842500\n",
      "2016-10-21 06:00:29,910 Epoch[1] Batch [250]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.848125\n",
      "2016-10-21 06:01:50,213 Epoch[1] Batch [300]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.844375\n",
      "2016-10-21 06:03:10,518 Epoch[1] Batch [350]\tSpeed: 19.92 samples/sec\tTrain-accuracy=0.853750\n"
     ]
    }
   ],
   "source": [
    "get_model('http://data.mxnet.io/models/imagenet-11k/resnet-152/resnet-152', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, 256)\n",
    "fit(new_sym, new_args, aux_params, train, val, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
